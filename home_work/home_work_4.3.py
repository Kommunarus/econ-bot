from langchain.agents.middleware import wrap_model_call, wrap_tool_call
from langchain.tools import tool
from dotenv import load_dotenv
import os
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
import time
import logging
import json


logging.basicConfig(
    filename="chat_session.log",
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    encoding="utf-8"
)

# –ó–∞–ø–æ–ª–Ω–∏—Ç–µ —Ü–µ–Ω—ã –¥–ª—è –º–æ–¥–µ–ª–µ–π (–≤ USD –∑–∞ 1M —Ç–æ–∫–µ–Ω–æ–≤)
# –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ü–µ–Ω—ã –∏ –¥–æ–±–∞–≤—å—Ç–µ –¥—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏
PRICES = {"gpt-4o-mini": {"input": 0.15, "output": 0.60},
          "openai/gpt-oss-20b": {"input": 1.25, "output": 10.00},}

# –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
CONFIG = {
    "snapshot_interval": 5,  # –∫–∞–∂–¥—ã–µ N –∑–∞–ø—Ä–æ—Å–æ–≤ –≤—ã–≤–æ–¥–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    "budget_limit_usd": 10.0,  # –ª–∏–º–∏—Ç –±—é–¥–∂–µ—Ç–∞
    "save_to_file": True,  # —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ –≤ —Ñ–∞–π–ª
    "output_file": "metrics.json",
}

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–µ—Ç—Ä–∏–∫
metrics = {
    "total_calls": 0,
    "successful_calls": 0,
    "failed_calls": 0,

    # –¢–æ–∫–µ–Ω—ã
    "input_tokens": 0,
    "output_tokens": 0,

    # –°—Ç–æ–∏–º–æ—Å—Ç—å
    "total_cost_usd": 0.0,

    # –õ–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)
    "latencies": [],

    # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
    "tools_used": {},  # {"tool_name": count}

    # –û—à–∏–±–∫–∏
    "errors": [],  # [{"type": "...", "message": "...", "timestamp": ...}]
}

def count_tokens(res) -> int:
    metadata = res.usage_metadata
    input_tokens = metadata.get("input_tokens", 0)
    output_tokens = metadata.get("output_tokens", 0)
    metrics['input_tokens'] += input_tokens
    metrics['output_tokens'] += output_tokens

def percentile(p: float) -> float:
    """
    –í—ã—á–∏—Å–ª–∏—Ç—å –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å
    """
    arr = metrics['latencies']
    pr = sorted(arr)[int(p * len(arr))]
    return pr

def calculate_cost(model_name: str, res) -> float:
    prices = PRICES[model_name]
    metadata = res.usage_metadata
    input_tokens = metadata.get("input_tokens", 0)
    output_tokens = metadata.get("output_tokens", 0)
    cost_input = (input_tokens / 1_000_000) * prices["input"]
    cost_output = (output_tokens / 1_000_000) * prices["output"]
    metrics['total_cost_usd'] += (cost_input + cost_output)

def check_budget():
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω–µ –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏ –±—é–¥–∂–µ—Ç
    """
    if metrics["total_cost_usd"] >= CONFIG['budget_limit_usd']:
        logging.error("‚ùå –ü–æ—Ä–æ–≥ –±—é–¥–∂–µ—Ç–∞ –ø—Ä–µ–≤—ã—à–µ–Ω!")
        raise BudgetExceeded("–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –±—é–¥–∂–µ—Ç–∞")


class BudgetExceeded(Exception):
    """–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –±—é–¥–∂–µ—Ç–∞"""
    pass


@wrap_model_call
def metrics_model_wrapper(request, handler):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞ –¥–ª—è —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–∏
    """

    metrics['total_calls'] += 1
    start = time.time()
    try:
        response = handler(request)
        metrics['successful_calls'] += 1
    except Exception as e:
        metrics["failed_calls"] += 1
        metrics["errors"].append({
            "type": type(e).__name__,
            "message": str(e),
            "timestamp": time.time()
        })


    elapsed = time.time() - start
    metrics['latencies'].append(elapsed)

    result = response.result[0]

    count_tokens(result)
    calculate_cost(MODEL, result)
    check_budget()

    if metrics['total_calls'] % CONFIG['snapshot_interval'] == 0:
        print_snapshot()


    return response


@wrap_tool_call
def metrics_tool_wrapper(request, handler):
    """
    –û–±—ë—Ä—Ç–∫–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
    """
    tool_name = request.tool_call.get("name", "unknown")
    if metrics['tools_used'].get(tool_name):
        metrics['tools_used'][tool_name] += 1
    else:
        metrics['tools_used'][tool_name] = 1

    result = handler(request)
    return result


def print_snapshot():
    """
    –í—ã–≤–µ—Å—Ç–∏ —Ç–µ–∫—É—â–∏–π —Å–Ω–∏–º–æ–∫ –º–µ—Ç—Ä–∏–∫

    –ö—Ä–∞—Å–∏–≤–æ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–π—Ç–µ –∏ –≤—ã–≤–µ–¥–∏—Ç–µ:
    - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ (—É—Å–ø–µ—à–Ω—ã—Ö –∏ —Å –æ—à–∏–±–∫–∞–º–∏)
    - –¢–æ–∫–µ–Ω—ã (–≤—Ö–æ–¥ + –≤—ã—Ö–æ–¥)
    - –°—Ç–æ–∏–º–æ—Å—Ç—å (–≤ USD –∏ RUB)
    - –õ–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (—Å—Ä–µ–¥–Ω–µ–µ, P50, P95, P99)
    - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
    - –ü—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫
    """
    # –¶–≤–µ—Ç–∞ –¥–ª—è —Ç–µ—Ä–º–∏–Ω–∞–ª–∞
    COLORS = {
        'header': '\033[1;36m',  # –ì–æ–ª—É–±–æ–π –∂–∏—Ä–Ω—ã–π
        'success': '\033[0;32m',  # –ó–µ–ª–µ–Ω—ã–π
        'warning': '\033[0;33m',  # –ñ–µ–ª—Ç—ã–π
        'error': '\033[0;31m',  # –ö—Ä–∞—Å–Ω—ã–π
        'info': '\033[0;37m',  # –ë–µ–ª—ã–π
        'reset': '\033[0m'  # –°–±—Ä–æ—Å —Ü–≤–µ—Ç–∞
    }

    separator = "=" * 60

    print(f"\n{COLORS['header']}{separator}")
    print("üìä –ú–ï–¢–†–ò–ö–ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò")
    print(separator + COLORS['reset'])

    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    print(f"{COLORS['info']}üìà –û–°–ù–û–í–ù–´–ï –ü–û–ö–ê–ó–ê–¢–ï–õ–ò:{COLORS['reset']}")
    print(f"  –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤     : {metrics['total_calls']:>10}")
    print(f"  –£—Å–ø–µ—à–Ω—ã—Ö           : {COLORS['success']}{metrics['successful_calls']:>10}{COLORS['reset']}")
    print(f"  –° –æ—à–∏–±–∫–∞–º–∏         : {COLORS['error']}{metrics['failed_calls']:>10}{COLORS['reset']}")
    print()

    # –¢–æ–∫–µ–Ω—ã
    print(f"{COLORS['info']}üî§ –¢–û–ö–ï–ù–´:{COLORS['reset']}")
    print(f"  –í—Ö–æ–¥–Ω—ã–µ            : {metrics['input_tokens']:>10,}")
    print(f"  –í—ã—Ö–æ–¥–Ω—ã–µ           : {metrics['output_tokens']:>10,}")
    print()

    # –°—Ç–æ–∏–º–æ—Å—Ç—å
    print(f"{COLORS['info']}üí∞ –°–¢–û–ò–ú–û–°–¢–¨:{COLORS['reset']}")
    print(f"  USD                : {metrics['total_cost_usd']:>10.4f}$")
    print(f"  RUB                : {metrics['total_cost_usd'] * 80:>10.2f}‚ÇΩ")
    print()

    # –õ–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å
    if metrics['latencies']:
        print(f"{COLORS['info']}‚è±Ô∏è  –í–†–ï–ú–Ø –û–¢–í–ï–¢–ê (—Å–µ–∫):{COLORS['reset']}")
        print(f"  –ú–µ–¥–∏–∞–Ω–∞ (p50)      : {percentile(0.50):>10.3f}")
        print(f"  95-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å    : {percentile(0.95):>10.3f}")
        print(f"  99-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å    : {percentile(0.99):>10.3f}")
    print()

    # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
    if metrics['tools_used']:
        print(f"{COLORS['info']}üõ†Ô∏è  –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ù–´–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–´:{COLORS['reset']}")
        for name_tool, count_tool in metrics['tools_used'].items():
            print(f"  {name_tool:<18} : {count_tool:>10}")
    print()

    # –û—à–∏–±–∫–∏
    if metrics['errors']:
        print(f"{COLORS['info']}üêõ –û–®–ò–ë–ö–ò:{COLORS['reset']}")
        error_stats = {}
        total_errors = len(metrics['errors'])

        for error in metrics['errors']:
            error_type = error["type"]
            error_stats[error_type] = error_stats.get(error_type, 0) + 1

        for error_type, count in error_stats.items():
            percentage = (count / total_errors) * 100
            print(f"  {error_type:<18} : {count:>3} ({percentage:.1f}%)")

    print(f"{COLORS['header']}{separator}{COLORS['reset']}\n")


def save_metrics_to_file():
    """
    –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ JSON —Ñ–∞–π–ª

    """
    if CONFIG["save_to_file"]:
        with open(CONFIG["output_file"], "w", encoding="utf-8") as f:
            json.dump(metrics, f, ensure_ascii=False, indent=4)


# –¥–æ–±–∞–≤—å—Ç–µ –ø–∞—Ä—É –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (–º–æ–∂–Ω–æ –≤–∑—è—Ç—å –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —É—Ä–æ–∫–æ–≤)
@tool
def calculator(expression: str) -> str:
    """–í—ã—á–∏—Å–ª—è–µ—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é eval"""
    try:
        result = eval(expression)
        return f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}"
    except Exception as e:
        return f"–û—à–∏–±–∫–∞: {e}"


@tool
def text_analyzer(text: str) -> str:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç"""
    return f"–î–ª–∏–Ω–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤, –°–ª–æ–≤: {len(text.split())}"



# –°–æ–±–µ—Ä–∏—Ç–µ –≤—Å—ë —ç—Ç–æ –≤–º–µ—Å—Ç–µ –≤ –∞–≥–µ–Ω—Ç–∞ –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∫–æ–¥–∞
if __name__ == '__main__':
    load_dotenv('my.env')
    MODEL = os.getenv("MODEL")
    API_KEY = os.getenv("API_KEY")
    API_BASE = os.getenv("API_BASE")


    model = ChatOpenAI(
        model=MODEL,
        openai_api_key=API_KEY,
        openai_api_base=API_BASE,
        temperature=0.2
    )

    agent = create_agent(
        model=model,
        tools=[calculator, text_analyzer],
        middleware=[metrics_model_wrapper, metrics_tool_wrapper]
    )

    for i in range(20):
        response = agent.invoke({"messages": [{"role": "user", "content": ("–ü—Ä–∏–¥—É–º–∞–π —Å–ª—É—á–∞–π–Ω—É—é —Å—Ç—Ä–æ–∫—É –∏ —Å–∫–∞–∂–∏ –º–Ω–µ –µ–µ –¥–ª–∏–Ω—É")}]})

    print(response["messages"][-1].content)

    print_snapshot()
    save_metrics_to_file()

    # –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã
    
    #"""============================================================
    # üìä –ú–ï–¢–†–ò–ö–ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò
    # ============================================================
    # üìà –û–°–ù–û–í–ù–´–ï –ü–û–ö–ê–ó–ê–¢–ï–õ–ò:
    #   –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤     :        143
    #   –£—Å–ø–µ—à–Ω—ã—Ö           :        143
    #   –° –æ—à–∏–±–∫–∞–º–∏         :          0
    #
    # üî§ –¢–û–ö–ï–ù–´:
    #   –í—Ö–æ–¥–Ω—ã–µ            :     25,341
    #   –í—ã—Ö–æ–¥–Ω—ã–µ           :     10,682
    #
    # üí∞ –°–¢–û–ò–ú–û–°–¢–¨:
    #   USD                :     0.1385$
    #   RUB                :      11.08‚ÇΩ
    #
    # ‚è±Ô∏è  –í–†–ï–ú–Ø –û–¢–í–ï–¢–ê (—Å–µ–∫):
    #   –ú–µ–¥–∏–∞–Ω–∞ (p50)      :      0.568
    #   95-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å    :      0.969
    #   99-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å    :      1.376
    #
    # üõ†Ô∏è  –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ù–´–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–´:
    #   text_analyzer      :         23
    #   calculator         :         20
    #
    # ============================================================"""



    # """{
    #     "total_calls": 30,
    #     "successful_calls": 30,
    #     "failed_calls": 0,
    #     "input_tokens": 5275,
    #     "output_tokens": 2173,
    #     "total_cost_usd": 0.028323749999999998,
    #     "latencies": [
    #         0.565342903137207,
    #         0.4434645175933838,
    #         0.36585164070129395,
    #         0.8771374225616455,
    #         0.3719611167907715,
    #         0.6613559722900391,
    #         0.36299705505371094,
    #         0.754875898361206,
    #         0.3723795413970947,
    #         0.5855114459991455,
    #         0.5248761177062988,
    #         0.31168389320373535,
    #         0.5048840045928955,
    #         0.5550916194915771,
    #         0.45508623123168945,
    #         0.3711071014404297,
    #         1.1598353385925293,
    #         0.45343518257141113,
    #         0.47551918029785156,
    #         0.7197794914245605,
    #         0.3726918697357178,
    #         0.8751001358032227,
    #         0.4735255241394043,
    #         0.6945803165435791,
    #         0.36241650581359863,
    #         0.9971117973327637,
    #         0.5746011734008789,
    #         0.7053601741790771,
    #         0.45281147956848145,
    #         0.5526721477508545
    #     ],
    #     "tools_used": {
    #         "calculator": 6,
    #         "text_analyzer": 4
    #     },
    #     "errors": []
    # }"""